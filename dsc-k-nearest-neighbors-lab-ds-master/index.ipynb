{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll build a simple version of a **_K-Nearest Neigbors classifier_** from scratch, and train it to make predictions on a dataset!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "* Implement a basic KNN algorithm from scratch\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "You'll begin this lab by creating a classifier. To keep things simple, you'll be using a helper function, `euclidean()`, from the `spatial.distance` module of the `scipy` library. Import this function in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the `KNN` class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now: \n",
    "\n",
    "* Create an class called `KNN` \n",
    "* This class should contain two empty methods -- `fit` and `predict` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class with two empty methods - fit and predict\n",
    "class KNN:\n",
    "    \n",
    "    def fit():\n",
    "        pass\n",
    "    \n",
    "    def predict():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module scipy.spatial.distance in scipy.spatial:\n",
      "\n",
      "NAME\n",
      "    scipy.spatial.distance\n",
      "\n",
      "DESCRIPTION\n",
      "    =====================================================\n",
      "    Distance computations (:mod:`scipy.spatial.distance`)\n",
      "    =====================================================\n",
      "    \n",
      "    .. sectionauthor:: Damian Eads\n",
      "    \n",
      "    Function Reference\n",
      "    ------------------\n",
      "    \n",
      "    Distance matrix computation from a collection of raw observation vectors\n",
      "    stored in a rectangular array.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       pdist   -- pairwise distances between observation vectors.\n",
      "       cdist   -- distances between two collections of observation vectors\n",
      "       squareform -- convert distance matrix to a condensed one and vice versa\n",
      "       directed_hausdorff -- directed Hausdorff distance between arrays\n",
      "    \n",
      "    Predicates for checking the validity of distance matrices, both\n",
      "    condensed and redundant. Also contained in this module are functions\n",
      "    for computing the number of observations in a distance matrix.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       is_valid_dm -- checks for a valid distance matrix\n",
      "       is_valid_y  -- checks for a valid condensed distance matrix\n",
      "       num_obs_dm  -- # of observations in a distance matrix\n",
      "       num_obs_y   -- # of observations in a condensed distance matrix\n",
      "    \n",
      "    Distance functions between two numeric vectors ``u`` and ``v``. Computing\n",
      "    distances over a large collection of vectors is inefficient for these\n",
      "    functions. Use ``pdist`` for this purpose.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       braycurtis       -- the Bray-Curtis distance.\n",
      "       canberra         -- the Canberra distance.\n",
      "       chebyshev        -- the Chebyshev distance.\n",
      "       cityblock        -- the Manhattan distance.\n",
      "       correlation      -- the Correlation distance.\n",
      "       cosine           -- the Cosine distance.\n",
      "       euclidean        -- the Euclidean distance.\n",
      "       mahalanobis      -- the Mahalanobis distance.\n",
      "       minkowski        -- the Minkowski distance.\n",
      "       seuclidean       -- the normalized Euclidean distance.\n",
      "       sqeuclidean      -- the squared Euclidean distance.\n",
      "       wminkowski       -- (deprecated) alias of `minkowski`.\n",
      "    \n",
      "    Distance functions between two boolean vectors (representing sets) ``u`` and\n",
      "    ``v``.  As in the case of numerical vectors, ``pdist`` is more efficient for\n",
      "    computing the distances between all pairs.\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       dice             -- the Dice dissimilarity.\n",
      "       hamming          -- the Hamming distance.\n",
      "       jaccard          -- the Jaccard distance.\n",
      "       kulsinski        -- the Kulsinski distance.\n",
      "       rogerstanimoto   -- the Rogers-Tanimoto dissimilarity.\n",
      "       russellrao       -- the Russell-Rao dissimilarity.\n",
      "       sokalmichener    -- the Sokal-Michener dissimilarity.\n",
      "       sokalsneath      -- the Sokal-Sneath dissimilarity.\n",
      "       yule             -- the Yule dissimilarity.\n",
      "    \n",
      "    :func:`hamming` also operates over discrete numerical vectors.\n",
      "\n",
      "FUNCTIONS\n",
      "    braycurtis(u, v, w=None)\n",
      "        Compute the Bray-Curtis distance between two 1-D arrays.\n",
      "        \n",
      "        Bray-Curtis distance is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\sum{|u_i-v_i|} / \\sum{|u_i+v_i|}\n",
      "        \n",
      "        The Bray-Curtis distance is in the range [0, 1] if all coordinates are\n",
      "        positive, and is undefined if the inputs are of length zero.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        braycurtis : double\n",
      "            The Bray-Curtis distance between 1-D arrays `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.braycurtis([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.braycurtis([1, 1, 0], [0, 1, 0])\n",
      "        0.33333333333333331\n",
      "    \n",
      "    canberra(u, v, w=None)\n",
      "        Compute the Canberra distance between two 1-D arrays.\n",
      "        \n",
      "        The Canberra distance is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "             d(u,v) = \\sum_i \\frac{|u_i-v_i|}\n",
      "                                  {|u_i|+|v_i|}.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        canberra : double\n",
      "            The Canberra distance between vectors `u` and `v`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When `u[i]` and `v[i]` are 0 for given i, then the fraction 0/0 = 0 is\n",
      "        used in the calculation.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.canberra([1, 0, 0], [0, 1, 0])\n",
      "        2.0\n",
      "        >>> distance.canberra([1, 1, 0], [0, 1, 0])\n",
      "        1.0\n",
      "    \n",
      "    cdist(XA, XB, metric='euclidean', *args, **kwargs)\n",
      "        Compute distance between each pair of the two collections of inputs.\n",
      "        \n",
      "        See Notes for common calling conventions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        XA : ndarray\n",
      "            An :math:`m_A` by :math:`n` array of :math:`m_A`\n",
      "            original observations in an :math:`n`-dimensional space.\n",
      "            Inputs are converted to float type.\n",
      "        XB : ndarray\n",
      "            An :math:`m_B` by :math:`n` array of :math:`m_B`\n",
      "            original observations in an :math:`n`-dimensional space.\n",
      "            Inputs are converted to float type.\n",
      "        metric : str or callable, optional\n",
      "            The distance metric to use.  If a string, the distance function can be\n",
      "            'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation',\n",
      "            'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'kulsinski',\n",
      "            'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao',\n",
      "            'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n",
      "            'wminkowski', 'yule'.\n",
      "        *args : tuple. Deprecated.\n",
      "            Additional arguments should be passed as keyword arguments\n",
      "        **kwargs : dict, optional\n",
      "            Extra arguments to `metric`: refer to each metric documentation for a\n",
      "            list of all possible arguments.\n",
      "        \n",
      "            Some possible arguments:\n",
      "        \n",
      "            p : scalar\n",
      "            The p-norm to apply for Minkowski, weighted and unweighted.\n",
      "            Default: 2.\n",
      "        \n",
      "            w : ndarray\n",
      "            The weight vector for metrics that support weights (e.g., Minkowski).\n",
      "        \n",
      "            V : ndarray\n",
      "            The variance vector for standardized Euclidean.\n",
      "            Default: var(vstack([XA, XB]), axis=0, ddof=1)\n",
      "        \n",
      "            VI : ndarray\n",
      "            The inverse of the covariance matrix for Mahalanobis.\n",
      "            Default: inv(cov(vstack([XA, XB].T))).T\n",
      "        \n",
      "            out : ndarray\n",
      "            The output array\n",
      "            If not None, the distance matrix Y is stored in this array.\n",
      "            Note: metric independent, it will become a regular keyword arg in a\n",
      "            future scipy version\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Y : ndarray\n",
      "            A :math:`m_A` by :math:`m_B` distance matrix is returned.\n",
      "            For each :math:`i` and :math:`j`, the metric\n",
      "            ``dist(u=XA[i], v=XB[j])`` is computed and stored in the\n",
      "            :math:`ij` th entry.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            An exception is thrown if `XA` and `XB` do not have\n",
      "            the same number of columns.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The following are common calling conventions:\n",
      "        \n",
      "        1. ``Y = cdist(XA, XB, 'euclidean')``\n",
      "        \n",
      "           Computes the distance between :math:`m` points using\n",
      "           Euclidean distance (2-norm) as the distance metric between the\n",
      "           points. The points are arranged as :math:`m`\n",
      "           :math:`n`-dimensional row vectors in the matrix X.\n",
      "        \n",
      "        2. ``Y = cdist(XA, XB, 'minkowski', p=2.)``\n",
      "        \n",
      "           Computes the distances using the Minkowski distance\n",
      "           :math:`||u-v||_p` (:math:`p`-norm) where :math:`p \\geq 1`.\n",
      "        \n",
      "        3. ``Y = cdist(XA, XB, 'cityblock')``\n",
      "        \n",
      "           Computes the city block or Manhattan distance between the\n",
      "           points.\n",
      "        \n",
      "        4. ``Y = cdist(XA, XB, 'seuclidean', V=None)``\n",
      "        \n",
      "           Computes the standardized Euclidean distance. The standardized\n",
      "           Euclidean distance between two n-vectors ``u`` and ``v`` is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              \\sqrt{\\sum {(u_i-v_i)^2 / V[x_i]}}.\n",
      "        \n",
      "           V is the variance vector; V[i] is the variance computed over all\n",
      "           the i'th components of the points. If not passed, it is\n",
      "           automatically computed.\n",
      "        \n",
      "        5. ``Y = cdist(XA, XB, 'sqeuclidean')``\n",
      "        \n",
      "           Computes the squared Euclidean distance :math:`||u-v||_2^2` between\n",
      "           the vectors.\n",
      "        \n",
      "        6. ``Y = cdist(XA, XB, 'cosine')``\n",
      "        \n",
      "           Computes the cosine distance between vectors u and v,\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              1 - \\frac{u \\cdot v}\n",
      "                       {{||u||}_2 {||v||}_2}\n",
      "        \n",
      "           where :math:`||*||_2` is the 2-norm of its argument ``*``, and\n",
      "           :math:`u \\cdot v` is the dot product of :math:`u` and :math:`v`.\n",
      "        \n",
      "        7. ``Y = cdist(XA, XB, 'correlation')``\n",
      "        \n",
      "           Computes the correlation distance between vectors u and v. This is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              1 - \\frac{(u - \\bar{u}) \\cdot (v - \\bar{v})}\n",
      "                       {{||(u - \\bar{u})||}_2 {||(v - \\bar{v})||}_2}\n",
      "        \n",
      "           where :math:`\\bar{v}` is the mean of the elements of vector v,\n",
      "           and :math:`x \\cdot y` is the dot product of :math:`x` and :math:`y`.\n",
      "        \n",
      "        \n",
      "        8. ``Y = cdist(XA, XB, 'hamming')``\n",
      "        \n",
      "           Computes the normalized Hamming distance, or the proportion of\n",
      "           those vector elements between two n-vectors ``u`` and ``v``\n",
      "           which disagree. To save memory, the matrix ``X`` can be of type\n",
      "           boolean.\n",
      "        \n",
      "        9. ``Y = cdist(XA, XB, 'jaccard')``\n",
      "        \n",
      "           Computes the Jaccard distance between the points. Given two\n",
      "           vectors, ``u`` and ``v``, the Jaccard distance is the\n",
      "           proportion of those elements ``u[i]`` and ``v[i]`` that\n",
      "           disagree where at least one of them is non-zero.\n",
      "        \n",
      "        10. ``Y = cdist(XA, XB, 'chebyshev')``\n",
      "        \n",
      "           Computes the Chebyshev distance between the points. The\n",
      "           Chebyshev distance between two n-vectors ``u`` and ``v`` is the\n",
      "           maximum norm-1 distance between their respective elements. More\n",
      "           precisely, the distance is given by\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              d(u,v) = \\max_i {|u_i-v_i|}.\n",
      "        \n",
      "        11. ``Y = cdist(XA, XB, 'canberra')``\n",
      "        \n",
      "           Computes the Canberra distance between the points. The\n",
      "           Canberra distance between two points ``u`` and ``v`` is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "             d(u,v) = \\sum_i \\frac{|u_i-v_i|}\n",
      "                                  {|u_i|+|v_i|}.\n",
      "        \n",
      "        12. ``Y = cdist(XA, XB, 'braycurtis')``\n",
      "        \n",
      "           Computes the Bray-Curtis distance between the points. The\n",
      "           Bray-Curtis distance between two points ``u`` and ``v`` is\n",
      "        \n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "                d(u,v) = \\frac{\\sum_i (|u_i-v_i|)}\n",
      "                              {\\sum_i (|u_i+v_i|)}\n",
      "        \n",
      "        13. ``Y = cdist(XA, XB, 'mahalanobis', VI=None)``\n",
      "        \n",
      "           Computes the Mahalanobis distance between the points. The\n",
      "           Mahalanobis distance between two points ``u`` and ``v`` is\n",
      "           :math:`\\sqrt{(u-v)(1/V)(u-v)^T}` where :math:`(1/V)` (the ``VI``\n",
      "           variable) is the inverse covariance. If ``VI`` is not None,\n",
      "           ``VI`` will be used as the inverse covariance matrix.\n",
      "        \n",
      "        14. ``Y = cdist(XA, XB, 'yule')``\n",
      "        \n",
      "           Computes the Yule distance between the boolean\n",
      "           vectors. (see `yule` function documentation)\n",
      "        \n",
      "        15. ``Y = cdist(XA, XB, 'matching')``\n",
      "        \n",
      "           Synonym for 'hamming'.\n",
      "        \n",
      "        16. ``Y = cdist(XA, XB, 'dice')``\n",
      "        \n",
      "           Computes the Dice distance between the boolean vectors. (see\n",
      "           `dice` function documentation)\n",
      "        \n",
      "        17. ``Y = cdist(XA, XB, 'kulsinski')``\n",
      "        \n",
      "           Computes the Kulsinski distance between the boolean\n",
      "           vectors. (see `kulsinski` function documentation)\n",
      "        \n",
      "        18. ``Y = cdist(XA, XB, 'rogerstanimoto')``\n",
      "        \n",
      "           Computes the Rogers-Tanimoto distance between the boolean\n",
      "           vectors. (see `rogerstanimoto` function documentation)\n",
      "        \n",
      "        19. ``Y = cdist(XA, XB, 'russellrao')``\n",
      "        \n",
      "           Computes the Russell-Rao distance between the boolean\n",
      "           vectors. (see `russellrao` function documentation)\n",
      "        \n",
      "        20. ``Y = cdist(XA, XB, 'sokalmichener')``\n",
      "        \n",
      "           Computes the Sokal-Michener distance between the boolean\n",
      "           vectors. (see `sokalmichener` function documentation)\n",
      "        \n",
      "        21. ``Y = cdist(XA, XB, 'sokalsneath')``\n",
      "        \n",
      "           Computes the Sokal-Sneath distance between the vectors. (see\n",
      "           `sokalsneath` function documentation)\n",
      "        \n",
      "        \n",
      "        22. ``Y = cdist(XA, XB, 'wminkowski', p=2., w=w)``\n",
      "        \n",
      "           Computes the weighted Minkowski distance between the\n",
      "           vectors. (see `wminkowski` function documentation)\n",
      "        \n",
      "        23. ``Y = cdist(XA, XB, f)``\n",
      "        \n",
      "           Computes the distance between all pairs of vectors in X\n",
      "           using the user supplied 2-arity function f. For example,\n",
      "           Euclidean distance between the vectors could be computed\n",
      "           as follows::\n",
      "        \n",
      "             dm = cdist(XA, XB, lambda u, v: np.sqrt(((u-v)**2).sum()))\n",
      "        \n",
      "           Note that you should avoid passing a reference to one of\n",
      "           the distance functions defined in this library. For example,::\n",
      "        \n",
      "             dm = cdist(XA, XB, sokalsneath)\n",
      "        \n",
      "           would calculate the pair-wise distances between the vectors in\n",
      "           X using the Python function `sokalsneath`. This would result in\n",
      "           sokalsneath being called :math:`{n \\choose 2}` times, which\n",
      "           is inefficient. Instead, the optimized C version is more\n",
      "           efficient, and we call it using the following syntax::\n",
      "        \n",
      "             dm = cdist(XA, XB, 'sokalsneath')\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find the Euclidean distances between four 2-D coordinates:\n",
      "        \n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> coords = [(35.0456, -85.2672),\n",
      "        ...           (35.1174, -89.9711),\n",
      "        ...           (35.9728, -83.9422),\n",
      "        ...           (36.1667, -86.7833)]\n",
      "        >>> distance.cdist(coords, coords, 'euclidean')\n",
      "        array([[ 0.    ,  4.7044,  1.6172,  1.8856],\n",
      "               [ 4.7044,  0.    ,  6.0893,  3.3561],\n",
      "               [ 1.6172,  6.0893,  0.    ,  2.8477],\n",
      "               [ 1.8856,  3.3561,  2.8477,  0.    ]])\n",
      "        \n",
      "        \n",
      "        Find the Manhattan distance from a 3-D point to the corners of the unit\n",
      "        cube:\n",
      "        \n",
      "        >>> a = np.array([[0, 0, 0],\n",
      "        ...               [0, 0, 1],\n",
      "        ...               [0, 1, 0],\n",
      "        ...               [0, 1, 1],\n",
      "        ...               [1, 0, 0],\n",
      "        ...               [1, 0, 1],\n",
      "        ...               [1, 1, 0],\n",
      "        ...               [1, 1, 1]])\n",
      "        >>> b = np.array([[ 0.1,  0.2,  0.4]])\n",
      "        >>> distance.cdist(a, b, 'cityblock')\n",
      "        array([[ 0.7],\n",
      "               [ 0.9],\n",
      "               [ 1.3],\n",
      "               [ 1.5],\n",
      "               [ 1.5],\n",
      "               [ 1.7],\n",
      "               [ 2.1],\n",
      "               [ 2.3]])\n",
      "    \n",
      "    chebyshev(u, v, w=None)\n",
      "        Compute the Chebyshev distance.\n",
      "        \n",
      "        Computes the Chebyshev distance between two 1-D arrays `u` and `v`,\n",
      "        which is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\max_i {|u_i-v_i|}.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input vector.\n",
      "        v : (N,) array_like\n",
      "            Input vector.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chebyshev : double\n",
      "            The Chebyshev distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.chebyshev([1, 0, 0], [0, 1, 0])\n",
      "        1\n",
      "        >>> distance.chebyshev([1, 1, 0], [0, 1, 0])\n",
      "        1\n",
      "    \n",
      "    cityblock(u, v, w=None)\n",
      "        Compute the City Block (Manhattan) distance.\n",
      "        \n",
      "        Computes the Manhattan distance between two 1-D arrays `u` and `v`,\n",
      "        which is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\sum_i {\\left| u_i - v_i \\right|}.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        cityblock : double\n",
      "            The City Block (Manhattan) distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.cityblock([1, 0, 0], [0, 1, 0])\n",
      "        2\n",
      "        >>> distance.cityblock([1, 0, 0], [0, 2, 0])\n",
      "        3\n",
      "        >>> distance.cityblock([1, 0, 0], [1, 1, 0])\n",
      "        1\n",
      "    \n",
      "    correlation(u, v, w=None, centered=True)\n",
      "        Compute the correlation distance between two 1-D arrays.\n",
      "        \n",
      "        The correlation distance between `u` and `v`, is\n",
      "        defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            1 - \\frac{(u - \\bar{u}) \\cdot (v - \\bar{v})}\n",
      "                      {{||(u - \\bar{u})||}_2 {||(v - \\bar{v})||}_2}\n",
      "        \n",
      "        where :math:`\\bar{u}` is the mean of the elements of `u`\n",
      "        and :math:`x \\cdot y` is the dot product of :math:`x` and :math:`y`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        correlation : double\n",
      "            The correlation distance between 1-D array `u` and `v`.\n",
      "    \n",
      "    cosine(u, v, w=None)\n",
      "        Compute the Cosine distance between 1-D arrays.\n",
      "        \n",
      "        The Cosine distance between `u` and `v`, is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            1 - \\frac{u \\cdot v}\n",
      "                      {||u||_2 ||v||_2}.\n",
      "        \n",
      "        where :math:`u \\cdot v` is the dot product of :math:`u` and\n",
      "        :math:`v`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        cosine : double\n",
      "            The Cosine distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.cosine([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.cosine([100, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.cosine([1, 1, 0], [0, 1, 0])\n",
      "        0.29289321881345254\n",
      "    \n",
      "    dice(u, v, w=None)\n",
      "        Compute the Dice dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Dice dissimilarity between `u` and `v`, is\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "             \\frac{c_{TF} + c_{FT}}\n",
      "                  {2c_{TT} + c_{FT} + c_{TF}}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) ndarray, bool\n",
      "            Input 1-D array.\n",
      "        v : (N,) ndarray, bool\n",
      "            Input 1-D array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        dice : double\n",
      "            The Dice dissimilarity between 1-D arrays `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.dice([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.dice([1, 0, 0], [1, 1, 0])\n",
      "        0.3333333333333333\n",
      "        >>> distance.dice([1, 0, 0], [2, 0, 0])\n",
      "        -0.3333333333333333\n",
      "    \n",
      "    directed_hausdorff(u, v, seed=0)\n",
      "        Compute the directed Hausdorff distance between two N-D arrays.\n",
      "        \n",
      "        Distances between pairs are calculated using a Euclidean metric.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (M,N) ndarray\n",
      "            Input array.\n",
      "        v : (O,N) ndarray\n",
      "            Input array.\n",
      "        seed : int or None\n",
      "            Local `np.random.RandomState` seed. Default is 0, a random shuffling of\n",
      "            u and v that guarantees reproducibility.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        d : double\n",
      "            The directed Hausdorff distance between arrays `u` and `v`,\n",
      "        \n",
      "        index_1 : int\n",
      "            index of point contributing to Hausdorff pair in `u`\n",
      "        \n",
      "        index_2 : int\n",
      "            index of point contributing to Hausdorff pair in `v`\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Uses the early break technique and the random sampling approach\n",
      "        described by [1]_. Although worst-case performance is ``O(m * o)``\n",
      "        (as with the brute force algorithm), this is unlikely in practice\n",
      "        as the input data would have to require the algorithm to explore\n",
      "        every single point interaction, and after the algorithm shuffles\n",
      "        the input points at that. The best case performance is O(m), which\n",
      "        is satisfied by selecting an inner loop distance that is less than\n",
      "        cmax and leads to an early break as often as possible. The authors\n",
      "        have formally shown that the average runtime is closer to O(m).\n",
      "        \n",
      "        .. versionadded:: 0.19.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A. A. Taha and A. Hanbury, \"An efficient algorithm for\n",
      "               calculating the exact Hausdorff distance.\" IEEE Transactions On\n",
      "               Pattern Analysis And Machine Intelligence, vol. 37 pp. 2153-63,\n",
      "               2015.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.spatial.procrustes : Another similarity test for two data sets\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find the directed Hausdorff distance between two 2-D arrays of\n",
      "        coordinates:\n",
      "        \n",
      "        >>> from scipy.spatial.distance import directed_hausdorff\n",
      "        >>> u = np.array([(1.0, 0.0),\n",
      "        ...               (0.0, 1.0),\n",
      "        ...               (-1.0, 0.0),\n",
      "        ...               (0.0, -1.0)])\n",
      "        >>> v = np.array([(2.0, 0.0),\n",
      "        ...               (0.0, 2.0),\n",
      "        ...               (-2.0, 0.0),\n",
      "        ...               (0.0, -4.0)])\n",
      "        \n",
      "        >>> directed_hausdorff(u, v)[0]\n",
      "        2.23606797749979\n",
      "        >>> directed_hausdorff(v, u)[0]\n",
      "        3.0\n",
      "        \n",
      "        Find the general (symmetric) Hausdorff distance between two 2-D\n",
      "        arrays of coordinates:\n",
      "        \n",
      "        >>> max(directed_hausdorff(u, v)[0], directed_hausdorff(v, u)[0])\n",
      "        3.0\n",
      "        \n",
      "        Find the indices of the points that generate the Hausdorff distance\n",
      "        (the Hausdorff pair):\n",
      "        \n",
      "        >>> directed_hausdorff(v, u)[1:]\n",
      "        (3, 3)\n",
      "    \n",
      "    euclidean(u, v, w=None)\n",
      "        Computes the Euclidean distance between two 1-D arrays.\n",
      "        \n",
      "        The Euclidean distance between 1-D arrays `u` and `v`, is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           {||u-v||}_2\n",
      "        \n",
      "           \\left(\\sum{(w_i |(u_i - v_i)|^2)}\\right)^{1/2}\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        euclidean : double\n",
      "            The Euclidean distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.euclidean([1, 0, 0], [0, 1, 0])\n",
      "        1.4142135623730951\n",
      "        >>> distance.euclidean([1, 1, 0], [0, 1, 0])\n",
      "        1.0\n",
      "    \n",
      "    hamming(u, v, w=None)\n",
      "        Compute the Hamming distance between two 1-D arrays.\n",
      "        \n",
      "        The Hamming distance between 1-D arrays `u` and `v`, is simply the\n",
      "        proportion of disagreeing components in `u` and `v`. If `u` and `v` are\n",
      "        boolean vectors, the Hamming distance is\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\frac{c_{01} + c_{10}}{n}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hamming : double\n",
      "            The Hamming distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.hamming([1, 0, 0], [0, 1, 0])\n",
      "        0.66666666666666663\n",
      "        >>> distance.hamming([1, 0, 0], [1, 1, 0])\n",
      "        0.33333333333333331\n",
      "        >>> distance.hamming([1, 0, 0], [2, 0, 0])\n",
      "        0.33333333333333331\n",
      "        >>> distance.hamming([1, 0, 0], [3, 0, 0])\n",
      "        0.33333333333333331\n",
      "    \n",
      "    is_valid_dm(D, tol=0.0, throw=False, name='D', warning=False)\n",
      "        Return True if input array is a valid distance matrix.\n",
      "        \n",
      "        Distance matrices must be 2-dimensional numpy arrays.\n",
      "        They must have a zero-diagonal, and they must be symmetric.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        D : ndarray\n",
      "            The candidate object to test for validity.\n",
      "        tol : float, optional\n",
      "            The distance matrix should be symmetric. `tol` is the maximum\n",
      "            difference between entries ``ij`` and ``ji`` for the distance\n",
      "            metric to be considered symmetric.\n",
      "        throw : bool, optional\n",
      "            An exception is thrown if the distance matrix passed is not valid.\n",
      "        name : str, optional\n",
      "            The name of the variable to checked. This is useful if\n",
      "            throw is set to True so the offending variable can be identified\n",
      "            in the exception message when an exception is thrown.\n",
      "        warning : bool, optional\n",
      "            Instead of throwing an exception, a warning message is\n",
      "            raised.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        valid : bool\n",
      "            True if the variable `D` passed is a valid distance matrix.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Small numerical differences in `D` and `D.T` and non-zeroness of\n",
      "        the diagonal are ignored if they are within the tolerance specified\n",
      "        by `tol`.\n",
      "    \n",
      "    is_valid_y(y, warning=False, throw=False, name=None)\n",
      "        Return True if the input array is a valid condensed distance matrix.\n",
      "        \n",
      "        Condensed distance matrices must be 1-dimensional numpy arrays.\n",
      "        Their length must be a binomial coefficient :math:`{n \\choose 2}`\n",
      "        for some positive integer n.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : ndarray\n",
      "            The condensed distance matrix.\n",
      "        warning : bool, optional\n",
      "            Invokes a warning if the variable passed is not a valid\n",
      "            condensed distance matrix. The warning message explains why\n",
      "            the distance matrix is not valid.  `name` is used when\n",
      "            referencing the offending variable.\n",
      "        throw : bool, optional\n",
      "            Throws an exception if the variable passed is not a valid\n",
      "            condensed distance matrix.\n",
      "        name : bool, optional\n",
      "            Used when referencing the offending variable in the\n",
      "            warning or exception message.\n",
      "    \n",
      "    jaccard(u, v, w=None)\n",
      "        Compute the Jaccard-Needham dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Jaccard-Needham dissimilarity between 1-D boolean arrays `u` and `v`,\n",
      "        is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\frac{c_{TF} + c_{FT}}\n",
      "                {c_{TT} + c_{FT} + c_{TF}}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        jaccard : double\n",
      "            The Jaccard distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.jaccard([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.jaccard([1, 0, 0], [1, 1, 0])\n",
      "        0.5\n",
      "        >>> distance.jaccard([1, 0, 0], [1, 2, 0])\n",
      "        0.5\n",
      "        >>> distance.jaccard([1, 0, 0], [1, 1, 1])\n",
      "        0.66666666666666663\n",
      "    \n",
      "    kulsinski(u, v, w=None)\n",
      "        Compute the Kulsinski dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Kulsinski dissimilarity between two boolean 1-D arrays `u` and `v`,\n",
      "        is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "             \\frac{c_{TF} + c_{FT} - c_{TT} + n}\n",
      "                  {c_{FT} + c_{TF} + n}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kulsinski : double\n",
      "            The Kulsinski distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.kulsinski([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.kulsinski([1, 0, 0], [1, 1, 0])\n",
      "        0.75\n",
      "        >>> distance.kulsinski([1, 0, 0], [2, 1, 0])\n",
      "        0.33333333333333331\n",
      "        >>> distance.kulsinski([1, 0, 0], [3, 1, 0])\n",
      "        -0.5\n",
      "    \n",
      "    mahalanobis(u, v, VI)\n",
      "        Compute the Mahalanobis distance between two 1-D arrays.\n",
      "        \n",
      "        The Mahalanobis distance between 1-D arrays `u` and `v`, is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\sqrt{ (u-v) V^{-1} (u-v)^T }\n",
      "        \n",
      "        where ``V`` is the covariance matrix.  Note that the argument `VI`\n",
      "        is the inverse of ``V``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        VI : ndarray\n",
      "            The inverse of the covariance matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mahalanobis : double\n",
      "            The Mahalanobis distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> iv = [[1, 0.5, 0.5], [0.5, 1, 0.5], [0.5, 0.5, 1]]\n",
      "        >>> distance.mahalanobis([1, 0, 0], [0, 1, 0], iv)\n",
      "        1.0\n",
      "        >>> distance.mahalanobis([0, 2, 0], [0, 1, 0], iv)\n",
      "        1.0\n",
      "        >>> distance.mahalanobis([2, 0, 0], [0, 1, 0], iv)\n",
      "        1.7320508075688772\n",
      "    \n",
      "    matching(*args, **kwds)\n",
      "        `matching` is deprecated!\n",
      "        spatial.distance.matching is deprecated in scipy 1.0.0; use spatial.distance.hamming instead.\n",
      "        \n",
      "        \n",
      "            Compute the Hamming distance between two boolean 1-D arrays.\n",
      "        \n",
      "            This is a deprecated synonym for :func:`hamming`.\n",
      "    \n",
      "    minkowski(u, v, p=2, w=None)\n",
      "        Compute the Minkowski distance between two 1-D arrays.\n",
      "        \n",
      "        The Minkowski distance between 1-D arrays `u` and `v`,\n",
      "        is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           {||u-v||}_p = (\\sum{|u_i - v_i|^p})^{1/p}.\n",
      "        \n",
      "        \n",
      "           \\left(\\sum{w_i(|(u_i - v_i)|^p)}\\right)^{1/p}.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        p : int\n",
      "            The order of the norm of the difference :math:`{||u-v||}_p`.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        minkowski : double\n",
      "            The Minkowski distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.minkowski([1, 0, 0], [0, 1, 0], 1)\n",
      "        2.0\n",
      "        >>> distance.minkowski([1, 0, 0], [0, 1, 0], 2)\n",
      "        1.4142135623730951\n",
      "        >>> distance.minkowski([1, 0, 0], [0, 1, 0], 3)\n",
      "        1.2599210498948732\n",
      "        >>> distance.minkowski([1, 1, 0], [0, 1, 0], 1)\n",
      "        1.0\n",
      "        >>> distance.minkowski([1, 1, 0], [0, 1, 0], 2)\n",
      "        1.0\n",
      "        >>> distance.minkowski([1, 1, 0], [0, 1, 0], 3)\n",
      "        1.0\n",
      "    \n",
      "    num_obs_dm(d)\n",
      "        Return the number of original observations that correspond to a\n",
      "        square, redundant distance matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        d : ndarray\n",
      "            The target distance matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        num_obs_dm : int\n",
      "            The number of observations in the redundant distance matrix.\n",
      "    \n",
      "    num_obs_y(Y)\n",
      "        Return the number of original observations that correspond to a\n",
      "        condensed distance matrix.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        Y : ndarray\n",
      "            Condensed distance matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n : int\n",
      "            The number of observations in the condensed distance matrix `Y`.\n",
      "    \n",
      "    pdist(X, metric='euclidean', *args, **kwargs)\n",
      "        Pairwise distances between observations in n-dimensional space.\n",
      "        \n",
      "        See Notes for common calling conventions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : ndarray\n",
      "            An m by n array of m original observations in an\n",
      "            n-dimensional space.\n",
      "        metric : str or function, optional\n",
      "            The distance metric to use. The distance function can\n",
      "            be 'braycurtis', 'canberra', 'chebyshev', 'cityblock',\n",
      "            'correlation', 'cosine', 'dice', 'euclidean', 'hamming',\n",
      "            'jaccard', 'kulsinski', 'mahalanobis', 'matching',\n",
      "            'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n",
      "            'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'.\n",
      "        *args : tuple. Deprecated.\n",
      "            Additional arguments should be passed as keyword arguments\n",
      "        **kwargs : dict, optional\n",
      "            Extra arguments to `metric`: refer to each metric documentation for a\n",
      "            list of all possible arguments.\n",
      "        \n",
      "            Some possible arguments:\n",
      "        \n",
      "            p : scalar\n",
      "            The p-norm to apply for Minkowski, weighted and unweighted.\n",
      "            Default: 2.\n",
      "        \n",
      "            w : ndarray\n",
      "            The weight vector for metrics that support weights (e.g., Minkowski).\n",
      "        \n",
      "            V : ndarray\n",
      "            The variance vector for standardized Euclidean.\n",
      "            Default: var(X, axis=0, ddof=1)\n",
      "        \n",
      "            VI : ndarray\n",
      "            The inverse of the covariance matrix for Mahalanobis.\n",
      "            Default: inv(cov(X.T)).T\n",
      "        \n",
      "            out : ndarray.\n",
      "            The output array\n",
      "            If not None, condensed distance matrix Y is stored in this array.\n",
      "            Note: metric independent, it will become a regular keyword arg in a\n",
      "            future scipy version\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Y : ndarray\n",
      "            Returns a condensed distance matrix Y.  For\n",
      "            each :math:`i` and :math:`j` (where :math:`i<j<m`),where m is the number\n",
      "            of original observations. The metric ``dist(u=X[i], v=X[j])``\n",
      "            is computed and stored in entry ``ij``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        squareform : converts between condensed distance matrices and\n",
      "                     square distance matrices.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See ``squareform`` for information on how to calculate the index of\n",
      "        this entry or to convert the condensed distance matrix to a\n",
      "        redundant square matrix.\n",
      "        \n",
      "        The following are common calling conventions.\n",
      "        \n",
      "        1. ``Y = pdist(X, 'euclidean')``\n",
      "        \n",
      "           Computes the distance between m points using Euclidean distance\n",
      "           (2-norm) as the distance metric between the points. The points\n",
      "           are arranged as m n-dimensional row vectors in the matrix X.\n",
      "        \n",
      "        2. ``Y = pdist(X, 'minkowski', p=2.)``\n",
      "        \n",
      "           Computes the distances using the Minkowski distance\n",
      "           :math:`||u-v||_p` (p-norm) where :math:`p \\geq 1`.\n",
      "        \n",
      "        3. ``Y = pdist(X, 'cityblock')``\n",
      "        \n",
      "           Computes the city block or Manhattan distance between the\n",
      "           points.\n",
      "        \n",
      "        4. ``Y = pdist(X, 'seuclidean', V=None)``\n",
      "        \n",
      "           Computes the standardized Euclidean distance. The standardized\n",
      "           Euclidean distance between two n-vectors ``u`` and ``v`` is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              \\sqrt{\\sum {(u_i-v_i)^2 / V[x_i]}}\n",
      "        \n",
      "        \n",
      "           V is the variance vector; V[i] is the variance computed over all\n",
      "           the i'th components of the points.  If not passed, it is\n",
      "           automatically computed.\n",
      "        \n",
      "        5. ``Y = pdist(X, 'sqeuclidean')``\n",
      "        \n",
      "           Computes the squared Euclidean distance :math:`||u-v||_2^2` between\n",
      "           the vectors.\n",
      "        \n",
      "        6. ``Y = pdist(X, 'cosine')``\n",
      "        \n",
      "           Computes the cosine distance between vectors u and v,\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              1 - \\frac{u \\cdot v}\n",
      "                       {{||u||}_2 {||v||}_2}\n",
      "        \n",
      "           where :math:`||*||_2` is the 2-norm of its argument ``*``, and\n",
      "           :math:`u \\cdot v` is the dot product of ``u`` and ``v``.\n",
      "        \n",
      "        7. ``Y = pdist(X, 'correlation')``\n",
      "        \n",
      "           Computes the correlation distance between vectors u and v. This is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              1 - \\frac{(u - \\bar{u}) \\cdot (v - \\bar{v})}\n",
      "                       {{||(u - \\bar{u})||}_2 {||(v - \\bar{v})||}_2}\n",
      "        \n",
      "           where :math:`\\bar{v}` is the mean of the elements of vector v,\n",
      "           and :math:`x \\cdot y` is the dot product of :math:`x` and :math:`y`.\n",
      "        \n",
      "        8. ``Y = pdist(X, 'hamming')``\n",
      "        \n",
      "           Computes the normalized Hamming distance, or the proportion of\n",
      "           those vector elements between two n-vectors ``u`` and ``v``\n",
      "           which disagree. To save memory, the matrix ``X`` can be of type\n",
      "           boolean.\n",
      "        \n",
      "        9. ``Y = pdist(X, 'jaccard')``\n",
      "        \n",
      "           Computes the Jaccard distance between the points. Given two\n",
      "           vectors, ``u`` and ``v``, the Jaccard distance is the\n",
      "           proportion of those elements ``u[i]`` and ``v[i]`` that\n",
      "           disagree.\n",
      "        \n",
      "        10. ``Y = pdist(X, 'chebyshev')``\n",
      "        \n",
      "           Computes the Chebyshev distance between the points. The\n",
      "           Chebyshev distance between two n-vectors ``u`` and ``v`` is the\n",
      "           maximum norm-1 distance between their respective elements. More\n",
      "           precisely, the distance is given by\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "              d(u,v) = \\max_i {|u_i-v_i|}\n",
      "        \n",
      "        11. ``Y = pdist(X, 'canberra')``\n",
      "        \n",
      "           Computes the Canberra distance between the points. The\n",
      "           Canberra distance between two points ``u`` and ``v`` is\n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "             d(u,v) = \\sum_i \\frac{|u_i-v_i|}\n",
      "                                  {|u_i|+|v_i|}\n",
      "        \n",
      "        \n",
      "        12. ``Y = pdist(X, 'braycurtis')``\n",
      "        \n",
      "           Computes the Bray-Curtis distance between the points. The\n",
      "           Bray-Curtis distance between two points ``u`` and ``v`` is\n",
      "        \n",
      "        \n",
      "           .. math::\n",
      "        \n",
      "                d(u,v) = \\frac{\\sum_i {|u_i-v_i|}}\n",
      "                               {\\sum_i {|u_i+v_i|}}\n",
      "        \n",
      "        13. ``Y = pdist(X, 'mahalanobis', VI=None)``\n",
      "        \n",
      "           Computes the Mahalanobis distance between the points. The\n",
      "           Mahalanobis distance between two points ``u`` and ``v`` is\n",
      "           :math:`\\sqrt{(u-v)(1/V)(u-v)^T}` where :math:`(1/V)` (the ``VI``\n",
      "           variable) is the inverse covariance. If ``VI`` is not None,\n",
      "           ``VI`` will be used as the inverse covariance matrix.\n",
      "        \n",
      "        14. ``Y = pdist(X, 'yule')``\n",
      "        \n",
      "           Computes the Yule distance between each pair of boolean\n",
      "           vectors. (see yule function documentation)\n",
      "        \n",
      "        15. ``Y = pdist(X, 'matching')``\n",
      "        \n",
      "           Synonym for 'hamming'.\n",
      "        \n",
      "        16. ``Y = pdist(X, 'dice')``\n",
      "        \n",
      "           Computes the Dice distance between each pair of boolean\n",
      "           vectors. (see dice function documentation)\n",
      "        \n",
      "        17. ``Y = pdist(X, 'kulsinski')``\n",
      "        \n",
      "           Computes the Kulsinski distance between each pair of\n",
      "           boolean vectors. (see kulsinski function documentation)\n",
      "        \n",
      "        18. ``Y = pdist(X, 'rogerstanimoto')``\n",
      "        \n",
      "           Computes the Rogers-Tanimoto distance between each pair of\n",
      "           boolean vectors. (see rogerstanimoto function documentation)\n",
      "        \n",
      "        19. ``Y = pdist(X, 'russellrao')``\n",
      "        \n",
      "           Computes the Russell-Rao distance between each pair of\n",
      "           boolean vectors. (see russellrao function documentation)\n",
      "        \n",
      "        20. ``Y = pdist(X, 'sokalmichener')``\n",
      "        \n",
      "           Computes the Sokal-Michener distance between each pair of\n",
      "           boolean vectors. (see sokalmichener function documentation)\n",
      "        \n",
      "        21. ``Y = pdist(X, 'sokalsneath')``\n",
      "        \n",
      "           Computes the Sokal-Sneath distance between each pair of\n",
      "           boolean vectors. (see sokalsneath function documentation)\n",
      "        \n",
      "        22. ``Y = pdist(X, 'wminkowski', p=2, w=w)``\n",
      "        \n",
      "           Computes the weighted Minkowski distance between each pair of\n",
      "           vectors. (see wminkowski function documentation)\n",
      "        \n",
      "        23. ``Y = pdist(X, f)``\n",
      "        \n",
      "           Computes the distance between all pairs of vectors in X\n",
      "           using the user supplied 2-arity function f. For example,\n",
      "           Euclidean distance between the vectors could be computed\n",
      "           as follows::\n",
      "        \n",
      "             dm = pdist(X, lambda u, v: np.sqrt(((u-v)**2).sum()))\n",
      "        \n",
      "           Note that you should avoid passing a reference to one of\n",
      "           the distance functions defined in this library. For example,::\n",
      "        \n",
      "             dm = pdist(X, sokalsneath)\n",
      "        \n",
      "           would calculate the pair-wise distances between the vectors in\n",
      "           X using the Python function sokalsneath. This would result in\n",
      "           sokalsneath being called :math:`{n \\choose 2}` times, which\n",
      "           is inefficient. Instead, the optimized C version is more\n",
      "           efficient, and we call it using the following syntax.::\n",
      "        \n",
      "             dm = pdist(X, 'sokalsneath')\n",
      "    \n",
      "    rogerstanimoto(u, v, w=None)\n",
      "        Compute the Rogers-Tanimoto dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Rogers-Tanimoto dissimilarity between two boolean 1-D arrays\n",
      "        `u` and `v`, is defined as\n",
      "        \n",
      "        .. math::\n",
      "           \\frac{R}\n",
      "                {c_{TT} + c_{FF} + R}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n` and :math:`R = 2(c_{TF} + c_{FT})`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rogerstanimoto : double\n",
      "            The Rogers-Tanimoto dissimilarity between vectors\n",
      "            `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.rogerstanimoto([1, 0, 0], [0, 1, 0])\n",
      "        0.8\n",
      "        >>> distance.rogerstanimoto([1, 0, 0], [1, 1, 0])\n",
      "        0.5\n",
      "        >>> distance.rogerstanimoto([1, 0, 0], [2, 0, 0])\n",
      "        -1.0\n",
      "    \n",
      "    russellrao(u, v, w=None)\n",
      "        Compute the Russell-Rao dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Russell-Rao dissimilarity between two boolean 1-D arrays, `u` and\n",
      "        `v`, is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "          \\frac{n - c_{TT}}\n",
      "               {n}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        russellrao : double\n",
      "            The Russell-Rao dissimilarity between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.russellrao([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.russellrao([1, 0, 0], [1, 1, 0])\n",
      "        0.6666666666666666\n",
      "        >>> distance.russellrao([1, 0, 0], [2, 0, 0])\n",
      "        0.3333333333333333\n",
      "    \n",
      "    seuclidean(u, v, V)\n",
      "        Return the standardized Euclidean distance between two 1-D arrays.\n",
      "        \n",
      "        The standardized Euclidean distance between `u` and `v`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        V : (N,) array_like\n",
      "            `V` is an 1-D array of component variances. It is usually computed\n",
      "            among a larger collection vectors.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        seuclidean : double\n",
      "            The standardized Euclidean distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.seuclidean([1, 0, 0], [0, 1, 0], [0.1, 0.1, 0.1])\n",
      "        4.4721359549995796\n",
      "        >>> distance.seuclidean([1, 0, 0], [0, 1, 0], [1, 0.1, 0.1])\n",
      "        3.3166247903553998\n",
      "        >>> distance.seuclidean([1, 0, 0], [0, 1, 0], [10, 0.1, 0.1])\n",
      "        3.1780497164141406\n",
      "    \n",
      "    sokalmichener(u, v, w=None)\n",
      "        Compute the Sokal-Michener dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Sokal-Michener dissimilarity between boolean 1-D arrays `u` and `v`,\n",
      "        is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\frac{R}\n",
      "                {S + R}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n`, :math:`R = 2 * (c_{TF} + c_{FT})` and\n",
      "        :math:`S = c_{FF} + c_{TT}`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        sokalmichener : double\n",
      "            The Sokal-Michener dissimilarity between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.sokalmichener([1, 0, 0], [0, 1, 0])\n",
      "        0.8\n",
      "        >>> distance.sokalmichener([1, 0, 0], [1, 1, 0])\n",
      "        0.5\n",
      "        >>> distance.sokalmichener([1, 0, 0], [2, 0, 0])\n",
      "        -1.0\n",
      "    \n",
      "    sokalsneath(u, v, w=None)\n",
      "        Compute the Sokal-Sneath dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Sokal-Sneath dissimilarity between `u` and `v`,\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\frac{R}\n",
      "                {c_{TT} + R}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n` and :math:`R = 2(c_{TF} + c_{FT})`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        sokalsneath : double\n",
      "            The Sokal-Sneath dissimilarity between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.sokalsneath([1, 0, 0], [0, 1, 0])\n",
      "        1.0\n",
      "        >>> distance.sokalsneath([1, 0, 0], [1, 1, 0])\n",
      "        0.66666666666666663\n",
      "        >>> distance.sokalsneath([1, 0, 0], [2, 1, 0])\n",
      "        0.0\n",
      "        >>> distance.sokalsneath([1, 0, 0], [3, 1, 0])\n",
      "        -2.0\n",
      "    \n",
      "    sqeuclidean(u, v, w=None)\n",
      "        Compute the squared Euclidean distance between two 1-D arrays.\n",
      "        \n",
      "        The squared Euclidean distance between `u` and `v` is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           {||u-v||}_2^2\n",
      "        \n",
      "           \\left(\\sum{(w_i |(u_i - v_i)|^2)}\\right)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        sqeuclidean : double\n",
      "            The squared Euclidean distance between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.sqeuclidean([1, 0, 0], [0, 1, 0])\n",
      "        2.0\n",
      "        >>> distance.sqeuclidean([1, 1, 0], [0, 1, 0])\n",
      "        1.0\n",
      "    \n",
      "    squareform(X, force='no', checks=True)\n",
      "        Convert a vector-form distance vector to a square-form distance\n",
      "        matrix, and vice-versa.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : ndarray\n",
      "            Either a condensed or redundant distance matrix.\n",
      "        force : str, optional\n",
      "            As with MATLAB(TM), if force is equal to ``'tovector'`` or\n",
      "            ``'tomatrix'``, the input will be treated as a distance matrix or\n",
      "            distance vector respectively.\n",
      "        checks : bool, optional\n",
      "            If set to False, no checks will be made for matrix\n",
      "            symmetry nor zero diagonals. This is useful if it is known that\n",
      "            ``X - X.T1`` is small and ``diag(X)`` is close to zero.\n",
      "            These values are ignored any way so they do not disrupt the\n",
      "            squareform transformation.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Y : ndarray\n",
      "            If a condensed distance matrix is passed, a redundant one is\n",
      "            returned, or if a redundant one is passed, a condensed distance\n",
      "            matrix is returned.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        1. v = squareform(X)\n",
      "        \n",
      "           Given a square d-by-d symmetric distance matrix X,\n",
      "           ``v = squareform(X)`` returns a ``d * (d-1) / 2`` (or\n",
      "           :math:`{n \\choose 2}`) sized vector v.\n",
      "        \n",
      "          :math:`v[{n \\choose 2}-{n-i \\choose 2} + (j-i-1)]` is the distance\n",
      "          between points i and j. If X is non-square or asymmetric, an error\n",
      "          is returned.\n",
      "        \n",
      "        2. X = squareform(v)\n",
      "        \n",
      "          Given a ``d*(d-1)/2`` sized v for some integer ``d >= 2`` encoding\n",
      "          distances as described, ``X = squareform(v)`` returns a d by d distance\n",
      "          matrix X.  The ``X[i, j]`` and ``X[j, i]`` values are set to\n",
      "          :math:`v[{n \\choose 2}-{n-i \\choose 2} + (j-i-1)]` and all\n",
      "          diagonal elements are zero.\n",
      "        \n",
      "        In Scipy 0.19.0, ``squareform`` stopped casting all input types to\n",
      "        float64, and started returning arrays of the same dtype as the input.\n",
      "    \n",
      "    wminkowski(u, v, p, w)\n",
      "        Compute the weighted Minkowski distance between two 1-D arrays.\n",
      "        \n",
      "        The weighted Minkowski distance between `u` and `v`, defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           \\left(\\sum{(|w_i (u_i - v_i)|^p)}\\right)^{1/p}.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like\n",
      "            Input array.\n",
      "        v : (N,) array_like\n",
      "            Input array.\n",
      "        p : int\n",
      "            The order of the norm of the difference :math:`{||u-v||}_p`.\n",
      "        w : (N,) array_like\n",
      "            The weight vector.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        wminkowski : double\n",
      "            The weighted Minkowski distance between vectors `u` and `v`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `wminkowski` is DEPRECATED. It implements a definition where weights\n",
      "        are powered. It is recommended to use the weighted version of `minkowski`\n",
      "        instead. This function will be removed in a future version of scipy.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.wminkowski([1, 0, 0], [0, 1, 0], 1, np.ones(3))\n",
      "        2.0\n",
      "        >>> distance.wminkowski([1, 0, 0], [0, 1, 0], 2, np.ones(3))\n",
      "        1.4142135623730951\n",
      "        >>> distance.wminkowski([1, 0, 0], [0, 1, 0], 3, np.ones(3))\n",
      "        1.2599210498948732\n",
      "        >>> distance.wminkowski([1, 1, 0], [0, 1, 0], 1, np.ones(3))\n",
      "        1.0\n",
      "        >>> distance.wminkowski([1, 1, 0], [0, 1, 0], 2, np.ones(3))\n",
      "        1.0\n",
      "        >>> distance.wminkowski([1, 1, 0], [0, 1, 0], 3, np.ones(3))\n",
      "        1.0\n",
      "    \n",
      "    yule(u, v, w=None)\n",
      "        Compute the Yule dissimilarity between two boolean 1-D arrays.\n",
      "        \n",
      "        The Yule dissimilarity is defined as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "             \\frac{R}{c_{TT} * c_{FF} + \\frac{R}{2}}\n",
      "        \n",
      "        where :math:`c_{ij}` is the number of occurrences of\n",
      "        :math:`\\mathtt{u[k]} = i` and :math:`\\mathtt{v[k]} = j` for\n",
      "        :math:`k < n` and :math:`R = 2.0 * c_{TF} * c_{FT}`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u : (N,) array_like, bool\n",
      "            Input array.\n",
      "        v : (N,) array_like, bool\n",
      "            Input array.\n",
      "        w : (N,) array_like, optional\n",
      "            The weights for each value in `u` and `v`. Default is None,\n",
      "            which gives each value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        yule : double\n",
      "            The Yule dissimilarity between vectors `u` and `v`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.spatial import distance\n",
      "        >>> distance.yule([1, 0, 0], [0, 1, 0])\n",
      "        2.0\n",
      "        >>> distance.yule([1, 1, 0], [0, 1, 0])\n",
      "        0.0\n",
      "\n",
      "DATA\n",
      "    __all__ = ['braycurtis', 'canberra', 'cdist', 'chebyshev', 'cityblock'...\n",
      "\n",
      "FILE\n",
      "    /home/a00005987/.local/lib/python3.6/site-packages/scipy/spatial/distance.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.spatial.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comple the `fit()` method\n",
    "\n",
    "Recall that when \"fitting\" a KNN classifier, all you're really doing is storing the points and their corresponding labels. There's no actual \"fitting\" involved here, since all you need to do is store the data so that you can use it to calculate the nearest neighbors when the `predict()` method is called.\n",
    "\n",
    "The inputs for this function should be:\n",
    "\n",
    "* `self`: since this will be an instance method inside the `KNN` class \n",
    "* `X_train`: an array, each row represents a _vector_ for a given point in space  \n",
    "* `y_train`: the corresponding labels for each vector in `X_train`. The label at `y_train[0]` is the label that corresponds to the vector at `X_train[0]`, and so on  \n",
    "\n",
    "In the cell below, complete the `fit` method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X_train, y_train):\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    \n",
    "# This line updates the knn.fit method to point to the function you've just written\n",
    "KNN.fit = fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Next, you will write three helper functions to make things easier when completing the `predict()` method. \n",
    "\n",
    "In the cell below, complete the `_get_distances()` function. This function should:\n",
    "\n",
    "* Take in two arguments: `self` and `x`\n",
    "* Create an empty array, `distances`, to hold all the distances you're going to calculate\n",
    "* Enumerate through every item in `self.X_train`. For each item: \n",
    "    * Use the `euclidean()` function to get the distance between x and the current point from `X_train` \n",
    "    * Create a tuple containing the index and the distance (in that order!) and append it to the `distances` array \n",
    "* Return the `distances` array when a distance has been generated for all items in `self.X_train` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_distances(self, x):\n",
    "    distances = []\n",
    "    for ind, val in enumerate(self.X_train):\n",
    "        dist_to_i = euclidean(x, val)\n",
    "        distances.append((ind, dist_to_i))\n",
    "    return distances\n",
    "\n",
    "# This line attaches the function you just created as a method to KNN class \n",
    "KNN._get_distances = _get_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! You will now create a `_get_k_nearest()` function to retrieve indices of the k-nearest points. This function should:\n",
    "\n",
    "* Take three arguments:\n",
    "    * `self`\n",
    "    * `dists`: an array of tuples containing (index, distance), which will be output from the `_get_distances()` method. \n",
    "    * `k`: the number of nearest neighbors you want to return\n",
    "* Sort the `dists` array by distances values, which are the second element in each tuple\n",
    "* Return the first `k` tuples from the sorted array \n",
    "\n",
    "**_Hint:_** To easily sort on the second item in the tuples contained within the `dists` array, use the `sorted()` function and pass in lambda for the `key=` parameter. To sort on the second element of each tuple, you can just use `key=lambda x: x[1]`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_distances(self, x):\n",
    "    distances = []\n",
    "    for ind, val in enumerate(self.X_train):\n",
    "        dist_to_i = euclidean(x, val)\n",
    "        distances.append((ind, dist_to_i))\n",
    "    return distances\n",
    "\n",
    "# This line attaches the function you just created as a method to KNN class \n",
    "KNN._get_distances = _get_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final helper function you'll create will get the labels that correspond to each of the k-nearest point, and return the class that occurs the most. \n",
    "\n",
    "Complete the `_get_label_prediction()` function in the cell below. This function should:\n",
    "\n",
    "* Create a list containing the labels from `self.y_train` for each index in `k_nearest` (remember, each item in `k_nearest` is a tuple, and the index is stored as the first item in each tuple)\n",
    "* Get the total counts for each label (use `np.bincount()` and pass in the label array created in the previous step)\n",
    "* Get the index of the label with the highest overall count in counts (use `np.argmax()` for this, and pass in the counts created in the previous step) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_label_prediction(self, k_nearest):\n",
    "        \n",
    "    labels = [self.y_train[i] for i, _ in k_nearest]\n",
    "    counts = np.bincount(labels)\n",
    "    return np.argmax(counts)\n",
    "\n",
    "# This line attaches the function you just created as a method to KNN class\n",
    "KNN._get_label_prediction = _get_label_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, you now have all the ingredients needed to complete the `predict()` method.\n",
    "\n",
    "## Complete the `predict()` method\n",
    "\n",
    "This method does all the heavy lifting for KNN, so this will be a bit more complex than the `fit()` method. Here's an outline of how this method should work:\n",
    "\n",
    "* In addition to `self`, our `predict` function should take in two arguments: \n",
    "    * `X_test`: the points we want to classify\n",
    "    * `k`: which specifies the number of neighbors we should use to make the classification.  Set `k=3` as a default, but allow the user to update it if they choose \n",
    "* Your method will need to iterate through every item in `X_test`. For each item:\n",
    "    * Calculate the distance to all points in `X_train` by using the `._get_distances()` helper method \n",
    "    * Find the k-nearest points in `X_train` by using the `._get_k_nearest()` method \n",
    "    * Use the index values contained within the tuples returned by `._get_k_nearest()` method to get the corresponding labels for each of the nearest points  \n",
    "    * Determine which class is most represented in these labels and treat that as the prediction for this point. Append the prediction to `preds` \n",
    "* Once a prediction has been generated for every item in `X_test`, return `preds`\n",
    "\n",
    "Follow these instructions to complete the `predict()` method in the cell below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X_test, k=3):\n",
    "    preds = []\n",
    "    # Iterate through each item in X_test\n",
    "    for i in X_test:\n",
    "        # Get distances between i and each item in X_train\n",
    "        dists = self._get_distances(i)\n",
    "        k_nearest = self._get_k_nearest(dists, k)\n",
    "        predicted_label = self._get_label_prediction(k_nearest)\n",
    "        preds.append(predicted_label)\n",
    "    return preds\n",
    "\n",
    "# This line updates the knn.predict method to point to the function you've just written\n",
    "KNN.predict = predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now, try out your new KNN classifier on a sample dataset to see how well it works!\n",
    "\n",
    "## Test the KNN classifier\n",
    "\n",
    "In order to test the performance of your model, import the **_Iris dataset_**. Specifically: \n",
    "\n",
    "- Use the `load_iris()` function, which can be found inside of the `sklearn.datasets` module. Then call this function, and use the object it returns \n",
    "- Import `train_test_split()` from `sklearn.model_selection`, as well as `accuracy_score()` from `sklearn.metrics` \n",
    "- Assign the `.data` attribute of `iris` to `data` and the `.target` attribute to `target` \n",
    "\n",
    "Note that there are **_3 classes_** in the Iris dataset, making this a multi-categorical classification problem. This means that you can't use evaluation metrics that are meant for binary classification problems. For this, just stick to accuracy for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `train_test_split()` to split the data into training and test sets. Pass in the `data` and `target`, and set the `test_size` to 0.25 and `random_state` to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate the `KNN` class, and `fit` it to the data in `X_train` and the labels in `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit KNN\n",
    "knn = KNN()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the `.predict()` method to generate predictions for the data stored in `X_test`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the moment of truth! Test the accuracy of your predictions. In the cell below, complete the call to `accuracy_score()` by passing in `y_test` and `preds`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: {}\".format(accuracy_score(y_test, preds)))\n",
    "# Expected Output: Testing Accuracy: 0.9736842105263158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 97% accuracy! Not bad for a handwritten machine learning classifier!\n",
    "\n",
    "## Summary\n",
    "\n",
    "That was great! Next, you'll dive a little deeper into evaluating performance of a KNN algorithm!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
